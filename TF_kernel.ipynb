{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from ops import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "\n",
    "X = tf.placeholder(shape=[None, dim], dtype=tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(shape=[None, dim], dtype=tf.float32, name=\"Y\")\n",
    "\n",
    "energy_pos = energy_func(X)\n",
    "energy_neg = energy_func(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 150\n",
    "\n",
    "def get_median(v):\n",
    "###     v = tf.reshape(v, [-1])\n",
    "###     m = v.get_shape()[0]//2\n",
    "    ### v: [N,N,dim]\n",
    "    v = tf.transpose(v,[0,2,1]) ### [N,dim,N]\n",
    "    m = batchsize//2\n",
    "    return tf.reduce_min(tf.nn.top_k(v, m, sorted=False).values, axis=-1) ### [N,dim]\n",
    "\n",
    "### Eucleadian Kernel:\n",
    "def RBF_kernel(x_in, scale=1., bandwidth=-1, n=batchsize):\n",
    "    x = tf.reshape(x_in,[n,-1]) ### Necessary for median calculation!!! [N,dim]\n",
    "    \n",
    "    x1 = tf.expand_dims(x,axis=1) ### [none,1,dim]\n",
    "    x2 = tf.expand_dims(x,axis=0) ### [1,none,dim]\n",
    "    dist = x1 - x2 ### [none,none,dim]\n",
    "    \n",
    "###     dist2 = tf.reduce_sum( dist**2, axis=-1 ) ### [none,none]\n",
    "    dist2 = dist**2 ### [none,none,dim]\n",
    "    \n",
    "    if bandwidth < 0: ### using median trick\n",
    "        median = get_median(dist2) ### [N,dim]\n",
    "        bandwidth = tf.sqrt( 0.5 * median / tf.log( tf.cast(tf.shape(x)[0],dtype=tf.float32) +1) )\n",
    "        bandwidth = bandwidth / scale\n",
    "        bandwidth = tf.expand_dims(bandwidth,axis=1) ### [n,1,dim]\n",
    "        \n",
    "    kernel = - dist2 / bandwidth**2/ 2. ### [none,none,dim]\n",
    "    ################################\n",
    "#     #### Compute Kernel derivatives:\n",
    "#     dx_kernel = - tf.matmul(kernel, x) ### [N,N] @ [N,dim] = [N,dim]\n",
    "#     sum_kernel = tf.reduce_sum(kernel,axis=1,keepdims=True) ### [N,1]\n",
    "#     grad = dx_kernel + x*sum_kernel ### [N,dim] + [N,dim]*[N,1] = [N,dim]\n",
    "#     grad = grad / (bandwidth**2)\n",
    "    \n",
    "#     return (kernel,grad)\n",
    "    return kernel\n",
    "\n",
    "######################################################\n",
    "\n",
    "### Torus Kernel:\n",
    "def RBF_kernel_torus(x_in, scale=1., bandwidth=-1, n=batchsize):\n",
    "    x = tf.reshape(x_in,[n,-1]) ### Necessary for median calculation!!! [N,dim]\n",
    "    \n",
    "    x1 = tf.expand_dims(x,axis=1) ### [none,1,dim]\n",
    "    x2 = tf.expand_dims(x,axis=0) ### [1,none,dim]\n",
    "    \n",
    "    dist_cos = tf.cos(x1) - tf.cos(x2)\n",
    "    dist_sin = tf.sin(x1) - tf.sin(x2)\n",
    "    \n",
    "    dist2 = dist_cos**2 + dist_sin**2 ### [none,none,dim]\n",
    "###    dist2 = tf.reduce_sum( dist2, axis=-1 ) ### [none,none]\n",
    "    \n",
    "    if bandwidth < 0: ### using median trick\n",
    "        median = get_median(dist2) ### [N,dim]\n",
    "        bandwidth = tf.sqrt( 0.5 * median / tf.log( tf.cast(tf.shape(x)[0],dtype=tf.float32) +1) )\n",
    "        bandwidth = bandwidth / scale\n",
    "        bandwidth = tf.expand_dims(bandwidth,axis=1) ### [n,1,dim]\n",
    "        \n",
    "    kernel = - dist2 / bandwidth**2/ 2. ### [none,none,dim]\n",
    "\n",
    "#     kernel = tf.exp( tf.reduce_mean( - dist2 / bandwidth**2/ 2., axis=-1) ) ### [none,none]\n",
    "#     grad = - 2./bandwidth * tf.expand_dims(kernel,axis=-1) ### [none,none,1]\n",
    "#     grad = grad * ( dist_cos * tf.expand_dims(tf.sin(x),axis=0) - dist_sin * tf.expand_dims(tf.cos(x),axis=0) ) ### [none,none,dim]   \n",
    "#     grad = tf.reduce_sum(grad,axis=1) ### [none,dim]\n",
    "    \n",
    "#     return (kernel,grad)\n",
    "    return kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel(x):\n",
    "    X_euc = tf.transpose( tf.gather( tf.transpose(x),[0]) ) ### Euclidean\n",
    "    X_torus = tf.transpose( tf.gather( tf.transpose(x),[1]) ) ### Torus\n",
    "    \n",
    "    kernel_euc = RBF_kernel(X_euc) ### [none,none,dim1]\n",
    "    kernel_torus = RBF_kernel_torus(X_torus) ### [none,none,dim2]\n",
    "    \n",
    "    kernel = tf.concat([kernel_euc, kernel_torus], axis=-1) ### [N,N,dim]\n",
    "    kernel = tf.exp( tf.reduce_mean(kernel, axis=-1) ) ### [N,N]\n",
    "\n",
    "    ###grad_kernel = tf.gradients(kernel,[X])\n",
    "    \n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define BT Loops\n",
    "num_steps = tf.placeholder(shape=[], dtype=tf.int32, name=\"bt.steps\") ### 100\n",
    "stepsize = tf.placeholder(shape=[], dtype=tf.float32, name=\"ss\") ### 1e-1\n",
    "beta = tf.placeholder(shape=[], dtype=tf.float32, name=\"beta\") ### KbT: 2.494339 kJ/mol ### inverse temperature\n",
    "\n",
    "steps = tf.constant(0)\n",
    "E_g2 = tf.zeros(tf.shape(Y))\n",
    "c = lambda i, x, eg2: tf.less(i, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bt_step(counter, x, E_g2, stepsize=stepsize, beta=beta ):\n",
    "    \n",
    "    energy = energy_func(x)\n",
    "    force = - beta * tf.gradients(energy,[x])[0]\n",
    "    \n",
    "    kernel = compute_kernel(x)\n",
    "    grad_x2 = tf.gradients(kernel,[x])[0]\n",
    "    \n",
    "    grad_x1 = tf.stop_gradient( tf.matmul(kernel,force) / batchsize) ### [Ni,dim]\n",
    "    grad_x2 = tf.stop_gradient( grad_x2 / batchsize )\n",
    "    \n",
    "    grad_x = grad_x1 + grad_x2\n",
    "    \n",
    "    ### AdaGrad\n",
    "    decay_rate = 0.9\n",
    "    fudge_factor = 1e-6\n",
    "    \n",
    "    def f1(): return grad_x**2\n",
    "    def f2(): return decay_rate * E_g2 + (1. - decay_rate) * (grad_x ** 2)\n",
    "    E_g2 = tf.cond( \n",
    "        tf.equal(counter,tf.constant(0)) , \n",
    "        f1,\n",
    "        f2, \n",
    "    )         \n",
    "\n",
    "    adj_grad = tf.divide( grad_x, tf.sqrt(E_g2+fudge_factor) )\n",
    "\n",
    "    ################################\n",
    "    x = x + stepsize * adj_grad   \n",
    "    counter += 1\n",
    "    \n",
    "    return [counter, x, E_g2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps, Y_BT, _ = tf.while_loop(c, bt_step, [steps, Y, E_g2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### with tf.Session() as sess:\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "        \n",
    "        \n",
    "        # ---------------------\n",
    "        #  Boltzmann Transformer\n",
    "        # ---------------------\n",
    "        beta_set = 1.\n",
    "        stepsize_set = 5e-2 ### 1e-1\n",
    "        num_steps_set = 250\n",
    "        \n",
    "        if_annealing = True\n",
    "        anneal_steps = 50\n",
    "        beta_anneal = 0.3 * beta_set\n",
    "        \n",
    "        if if_annealing:\n",
    "            feed_dict={Y:neg_imgs,\n",
    "               beta:beta_anneal, num_steps:anneal_steps, stepsize:stepsize_set,\n",
    "               is_training:False, }\n",
    "            \n",
    "            neg_imgs = sess.run( Y_BT, feed_dict=feed_dict) ### [N,dims=2]            \n",
    "            neg_imgs = np.sign(np.sin(neg_imgs)) * np.arccos(np.cos(neg_imgs))\n",
    "        ##########\n",
    "        \n",
    "        feed_dict={Y:neg_imgs,\n",
    "           beta:beta_set, num_steps:num_steps_set, stepsize:stepsize_set,\n",
    "           is_training:False, }\n",
    "            \n",
    "        neg_imgs = sess.run( Y_BT, feed_dict=feed_dict) ### [N,dims=2] \n",
    "        neg_imgs = np.sign(np.sin(neg_imgs)) * np.arccos(np.cos(neg_imgs))\n",
    "        #############################################################\n",
    "            \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        feed_dict={X:pos_imgs, Y:neg_imgs, wt:pos_weight,\n",
    "                   is_training:True, lr:1e-4, reg:1e-2, }\n",
    "\n",
    "        _, _loss, _loss_lh, _loss_drift, _energy_pos, _energy_neg = sess.run(\n",
    "                [ train_op, loss, loss_lh, loss_drift, energy_pos, energy_neg ], feed_dict=feed_dict)        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
